{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "romance-finnish",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "selective-stopping",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/felgueira/miniconda3/envs/personal/lib/python3.7/site-packages/ipykernel_launcher.py:1: FutureWarning: Your version of xlrd is 1.2.0. In xlrd >= 2.0, only the xls format is supported. As a result, the openpyxl engine will be used if it is installed and the engine argument is not specified. Install openpyxl instead.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_excel(\"../data/raw.xlsx\", 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "random-shoulder",
   "metadata": {},
   "source": [
    "# Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "vietnamese-celtic",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Typos\n",
    "df = df.replace(\"iceland\", \"Iceland\")\n",
    "df = df.rename(columns={\"Framework_OutSystems\":\"Framework_Outsystems\"})\n",
    "\n",
    "# Data Types\n",
    "df[\"Avg_Salary\"] = df[\"Avg_Salary\"].astype(int)\n",
    "\n",
    "# Residence country is always Portugal so it's irrelevant\n",
    "df = df.drop(columns=\"Residence_Country\")\n",
    "\n",
    "# It's not clear how many hours part-time workers work. It's better to remove them from the scope of the project.\n",
    "df = df[df[\"Employment_Status\"] != \"Employed part-time\"]\n",
    "\n",
    "# Remove datapoints where salary is 0\n",
    "df = df[df.Avg_Salary!=0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ignored-scotland",
   "metadata": {},
   "source": [
    "# Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "flying-native",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [\"Employment_Status\",\n",
    "        \"Residence_District_Aggregated\",\n",
    "        \"Work_Company_Country\",\n",
    "        \"Job_Role_Original\",\n",
    "        \"Employer_Industry\",\n",
    "        \"Employer_Org_Type\",\n",
    "        \"Employer_Size\",\n",
    "        \"Avg_Salary\",\n",
    "        \"English_Level\",\n",
    "        \"Education_Level\",\n",
    "        \"Working_Experience\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "continental-balloon",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.loc[:,cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "protected-contribution",
   "metadata": {},
   "source": [
    "# Aggregate Work Company Country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "general-gothic",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace all work company countries with less than 19 points by \"Other\".\n",
    "# We assume that less than 19 points is not representative enough for the model to learn.\n",
    "values = df[\"Work_Company_Country\"].value_counts()[df[\"Work_Company_Country\"].value_counts()<19].index\n",
    "values = values.append(pd.Index([\"No specific country\"]))\n",
    "df.loc[:,\"Work_Company_Country\"] = df[\"Work_Company_Country\"].replace(values,\"Other\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adjustable-mystery",
   "metadata": {},
   "source": [
    "#Â Frameworks and Languages Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "italic-vulnerability",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning frameworks and languages when testing their use.\n",
    "\n",
    "#tool_cols = df.columns[df.columns.str.contains(\"Framework\") | df.columns.str.contains(\"Language\")]\n",
    "#for col in tool_cols:\n",
    "#    df[col] = df[col].replace(col.split(\"_\")[-1],1)\n",
    "#    df[col] = df[col].fillna(0)\n",
    "#    df[col] = df[col].astype(\"category\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "speaking-portsmouth",
   "metadata": {},
   "source": [
    "# Categoricals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "further-positive",
   "metadata": {},
   "outputs": [],
   "source": [
    "categoricals = df.dtypes[df.dtypes == object].index\n",
    "df[categoricals] = df[categoricals].astype(\"category\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "metric-penguin",
   "metadata": {},
   "source": [
    "# Drop NaNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "furnished-encoding",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3334, 11)\n",
      "(3081, 11)\n"
     ]
    }
   ],
   "source": [
    "# Drop all datapoints that have at least one missing feature.\n",
    "\n",
    "print(df.shape)\n",
    "df = df.dropna().reset_index(drop=True)\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pressed-mirror",
   "metadata": {},
   "source": [
    "# Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "auburn-cartoon",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_parquet(\"../data/cleaned.parquet\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:personal] *",
   "language": "python",
   "name": "conda-env-personal-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
